{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f7324ec-d371-4fe0-bd4a-7157d1ed468d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "We will use the GPU: NVIDIA A40\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "from TransformerGlow import AdamWeightDecayOptimizer, FactorTrainer\n",
    "import numpy as np\n",
    "import torch\n",
    "import random\n",
    "import pandas as pd\n",
    "import pickle\n",
    "# import os, sys\n",
    "# import time\n",
    "# import datetime\n",
    "# import torch.nn.functional as F\n",
    "# from torch import nn\n",
    "\n",
    "\n",
    "\n",
    "# random.seed(42)\n",
    "torch.manual_seed(42) \n",
    "if torch.cuda.is_available():\n",
    "  device = torch.device(\"cuda\")\n",
    "  print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "  print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "\n",
    "else:\n",
    "  print('No GPU available, using the CPU instead.')\n",
    "  device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7987088-74ad-4931-b0e8-b412fffa22e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_examples(embeddings, gen_labels, attribute_ids, logits, rand_seed=42 , train=True):\n",
    "    random.seed(rand_seed)\n",
    "    female_embeddings = []\n",
    "    male_embeddings = []\n",
    "    female_gen_labels = []\n",
    "    male_gen_labels = []\n",
    "    female_attribute_ids = []\n",
    "    male_attribute_ids = []\n",
    "    \n",
    "    for key,i in enumerate(gen_labels):\n",
    "        if i==0:\n",
    "            # print(logits[key])\n",
    "            if logits[key]<-0:\n",
    "                female_embeddings.append(embeddings[key])\n",
    "                female_gen_labels.append(i)\n",
    "                female_attribute_ids.append(attribute_ids[key])\n",
    "                # print(key)\n",
    "        else:\n",
    "            if logits[key]>0:\n",
    "                male_embeddings.append(embeddings[key])\n",
    "                male_gen_labels.append(i)\n",
    "                male_attribute_ids.append(attribute_ids[key])\n",
    "\n",
    "    random.shuffle(female_embeddings)\n",
    "    random.shuffle(male_embeddings)\n",
    "    female_embeddings_1 = female_embeddings[:int(len(female_embeddings)*0.5)].copy()\n",
    "    male_embeddings_1 = male_embeddings[:int(len(male_embeddings)*0.5)].copy()\n",
    "    female_embeddings_2 = female_embeddings[int(len(female_embeddings)*0.5):].copy()\n",
    "    male_embeddings_2 = male_embeddings[int(len(male_embeddings)*0.5):].copy()\n",
    "    # random.Random(rand_seed).shuffle(female_embeddings_2)\n",
    "    # random.Random(rand_seed).shuffle(male_embeddings_2)\n",
    "\n",
    "    female_data_pairs = [[x, y] for x, y in zip(female_embeddings_1, female_embeddings_2)]\n",
    "    male_data_pairs = [[x, y] for x, y in zip(male_embeddings_1, male_embeddings_2)]\n",
    "\n",
    "    gender_data_pairs = female_data_pairs + male_data_pairs\n",
    "    random.shuffle(gender_data_pairs)\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "    if train==True:\n",
    "        gender_data_pairs = torch.tensor(np.array(gender_data_pairs))\n",
    "        return gender_data_pairs\n",
    "\n",
    "    else:\n",
    "        female_data_pairs_test = torch.tensor(np.array(female_data_pairs))\n",
    "        male_data_pairs_test = torch.tensor(np.array(male_data_pairs))\n",
    "        return female_data_pairs_test, male_data_pairs_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a1757a2d-e0f6-41e3-9c78-d95f88734f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import random\n",
    "# train_limit = int(0.99*len(embeddings))\n",
    "# random.Random(4).shuffle(embeddings)\n",
    "# random.Random(4).shuffle(gen_labels)\n",
    "# random.Random(4).shuffle(attribute_ids)\n",
    "# train_embeddings = embeddings[:train_limit]\n",
    "# train_gen_labels = gen_labels[:train_limit]\n",
    "# train_attribute_ids = attribute_ids[:train_limit]\n",
    "\n",
    "# test_embeddings = embeddings[train_limit:]\n",
    "# test_gen_labels = gen_labels[train_limit:]\n",
    "# test_attribute_ids = attribute_ids[train_limit:]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c8a9257-4f49-478b-9bab-9ccf584d27a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import importlib\n",
    "# importlib.reload(FactorTrainer)\n",
    "\n",
    "# TransformerGlow = importlib.reload(FactorTrainer)\n",
    "# FactorTrainer = reload(FactorTrainer)\n",
    "\n",
    "FactorTrainer_config = {\n",
    "  \"n_factors\": 10,\n",
    "  # \"factor_dim\":211,\n",
    "  \"in_channel\": 768,\n",
    "  \"n_flow\": 6,\n",
    "  \"hidden_depth\": 2,\n",
    "  \"hidden_dim\": 100,\n",
    "# \"rho\": 0.999\n",
    "  \"rho\": 0.98\n",
    "}\n",
    "\n",
    "bertflow = FactorTrainer(FactorTrainer_config).cuda()\n",
    "\n",
    "no_decay = [\"bias\", \"LayerNorm.weight\"]\n",
    "optimizer_grouped_parameters= [\n",
    "        {\n",
    "            \"params\": [p for n, p in bertflow.glow.named_parameters()  \\\n",
    "                            if not any(nd in n for nd in no_decay)],  # Note only the parameters within bertflow.glow will be updated and the Transformer will be freezed during training.\n",
    "            \"weight_decay\": 0.01,\n",
    "        },\n",
    "        {\n",
    "            \"params\": [p for n, p in bertflow.glow.named_parameters()  \\\n",
    "                            if any(nd in n for nd in no_decay)],\n",
    "            \"weight_decay\": 0.0,\n",
    "        },\n",
    "    ]\n",
    "\n",
    "\n",
    "\n",
    "optimizer = AdamWeightDecayOptimizer(\n",
    "        params=optimizer_grouped_parameters, \n",
    "        lr=1e-3, \n",
    "        eps=1e-6,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf248f0f-2818-47fe-a6e2-0d4e4ee13574",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('../viz/2_attribute_embeddings_80000_150_tokens_balanced_2000/embeddings.pkl', 'rb') as f:\n",
    "#         embeddings = pickle.load(f)\n",
    "# with open('../viz/2_attribute_embeddings_80000_150_tokens_balanced_2000/gender.pkl', 'rb') as f:\n",
    "#         gen_labels = pickle.load(f)\n",
    "# with open('../viz/2_attribute_embeddings_80000_150_tokens_balanced_2000/token_ids.pkl', 'rb') as f:\n",
    "#         attribute_ids = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7589ff0-cd5b-491a-83fe-ad6bf5187d13",
   "metadata": {},
   "source": [
    "######### TRAIN MODEL ################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e733f0f-ac8f-45bf-a794-4b7303739ea1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36997\n",
      "epoch: 0\n",
      "tensor(1871.3604, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(-424.0946, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(-540.9125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(-657.1843, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(-608.1889, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(-667.6589, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(-719.4258, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(-667.8638, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(-749.1887, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(-803.5557, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(-799.0875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(-797.7902, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(-761.2063, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "epoch: 1\n",
      "tensor(-768.5020, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(-854.0918, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(-801.3319, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(-839.3717, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(-805.3947, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(-872.8585, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(-850.7683, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(-781.3176, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(-903.9509, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(-882.7072, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(-848.3700, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(-872.9957, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(-905.0061, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "epoch: 2\n",
      "tensor(-856.0896, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(-913.3151, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(-914.1139, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(-852.4922, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(-890.4973, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(-877.9984, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(-951.0664, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(-876.9772, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(-852.0279, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(-861.4399, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(-935.0697, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(-989.6359, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(-912.6635, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "epoch: 3\n",
      "tensor(-1022.3983, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(-971.5251, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(-982.2540, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(-1011.3744, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(-880.9448, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(-947.1896, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(-968.1291, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(-964.4794, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(-936.3256, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(-949.7159, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(-923.4232, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(-913.4702, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(-808.0255, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "attribute_pair = \"african_european\"\n",
    "model_path = \"bertflow_model_\"+attribute_pair\n",
    "if not os.path.exists(model_path):\n",
    "    os.makedirs(model_path)\n",
    "\n",
    "\n",
    "bertflow.train()\n",
    "\n",
    "# for jj in range(1,2):\n",
    "for iteration in range(2000,13000, 2000):\n",
    "    print(iteration)\n",
    "\n",
    "    with open('../1_viz/attribute_embeddings_'+attribute_pair+'/embeddings_'+str(iteration)+'.pkl', 'rb') as f:\n",
    "        embeddings = pickle.load(f)\n",
    "    with open('../1_viz/attribute_embeddings_'+attribute_pair+'/gender_'+str(iteration)+'.pkl', 'rb') as f:\n",
    "            gen_labels = pickle.load(f)\n",
    "    with open('../1_viz/attribute_embeddings_'+attribute_pair+'/token_ids_'+str(iteration)+'.pkl', 'rb') as f:\n",
    "            attribute_ids = pickle.load(f)\n",
    "    with open('../1_viz/attribute_embeddings_'+attribute_pair+'/logits_'+str(iteration)+'.pkl', 'rb') as f:\n",
    "            logits = pickle.load(f)\n",
    "    # with open('../1_viz/first_attribute_embeddings_'+attribute_pair+'/embeddings_'+str(iteration)+'.pkl', 'rb') as f:\n",
    "    #     embeddings = pickle.load(f)\n",
    "    # with open('../1_viz/first_attribute_embeddings_'+attribute_pair+'/gender_'+str(iteration)+'.pkl', 'rb') as f:\n",
    "    #         gen_labels = pickle.load(f)\n",
    "    # with open('../1_viz/first_attribute_embeddings_'+attribute_pair+'/token_ids_'+str(iteration)+'.pkl', 'rb') as f:\n",
    "    #         attribute_ids = pickle.load(f)\n",
    "    # # with open('../1_viz/first_attribute_embeddings_'+attribute_pair+'/logits_'+str(iteration)+'.pkl', 'rb') as f:\n",
    "    # #         logits = pickle.load(f)\n",
    "\n",
    "    for epoch in range(4):\n",
    "        # reload data shuffled\n",
    "        train_gender_data_pairs = get_examples(embeddings, gen_labels, attribute_ids, logits, rand_seed=epoch)\n",
    "        \n",
    "        \n",
    "        batch_size = 32\n",
    "        \n",
    "        \n",
    "        \n",
    "        # Create the DataLoaders for our training and validation sets.\n",
    "        # We'll take training samples in random order. \n",
    "        train_dataloader = DataLoader(\n",
    "                    train_gender_data_pairs,  # The training samples.\n",
    "                    sampler = RandomSampler(train_gender_data_pairs), # Select batches randomly\n",
    "                    batch_size = batch_size # Trains with this batch size.\n",
    "                )\n",
    "    \n",
    "       \n",
    "        print(\"epoch:\", epoch)\n",
    "        for step, batch in enumerate(train_dataloader):\n",
    "            # print(step)\n",
    "            # print(batch.shape)\n",
    "            # bertflow.train()\n",
    "            z, loss = bertflow(batch.to(device))  # Here z is the sentence embedding\n",
    "            if step%100==0:\n",
    "                print(loss)\n",
    "                print(loss, file=open('output.txt', 'a'))\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "        # if (iteration)%2000==0:\n",
    "        # # if (epoch+1)%4==0:\n",
    "        #     torch.save(bertflow, model_path+'/bertflow_rho_0999_factors_6_iterations_'+str(iteration)+'.pth')\n",
    "    torch.save(evalbertflow, model_path+'/bertflow_rho_0999_factors_'+n_factors+'.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "39a3c50e-74fe-408a-adb5-125e97132f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# attribute_pair = \"asian_european\"\n",
    "# model_path = \"bertflow_model_\"+attribute_pair\n",
    "# if not os.path.exists(model_path):\n",
    "#     os.makedirs(model_path)\n",
    "\n",
    "\n",
    "# bertflow.train()\n",
    "\n",
    "# for jj in range(1,2):\n",
    "#     for iteration in range(1500,31500,1500):\n",
    "#         print(iteration)\n",
    "    \n",
    "#         # with open('../1_viz/attribute_embeddings/embeddings_1000.pkl', 'rb') as f:\n",
    "#         #     embeddings = pickle.load(f)\n",
    "#         # with open('../1_viz/attribute_embeddings/gender_1000.pkl', 'rb') as f:\n",
    "#         #     gen_labels = pickle.load(f)\n",
    "#         # with open('../1_viz/attribute_embeddings/token_ids_1000.pkl', 'rb') as f:\n",
    "#         #     attribute_ids = pickle.load(f)\n",
    "#         with open('../1_viz/attribute_embeddings_'+attribute_pair+'/embeddings_'+str(jj)+'_'+str(iteration)+'.pkl', 'rb') as f:\n",
    "#             embeddings = pickle.load(f)\n",
    "#         with open('../1_viz/attribute_embeddings_'+attribute_pair+'/gender_'+str(jj)+'_'+str(iteration)+'.pkl', 'rb') as f:\n",
    "#                 gen_labels = pickle.load(f)\n",
    "#         with open('../1_viz/attribute_embeddings_'+attribute_pair+'/token_ids_'+str(jj)+'_'+str(iteration)+'.pkl', 'rb') as f:\n",
    "#                 attribute_ids = pickle.load(f)\n",
    "#         with open('../1_viz/attribute_embeddings_'+attribute_pair+'/logits_'+str(jj)+'_'+str(iteration)+'.pkl', 'rb') as f:\n",
    "#                 logits = pickle.load(f)\n",
    "    \n",
    "#         for epoch in range(1):\n",
    "#             # reload data shuffled\n",
    "#             train_gender_data_pairs = get_examples(embeddings, gen_labels, attribute_ids, logits, epoch)\n",
    "            \n",
    "            \n",
    "#             batch_size = 32\n",
    "            \n",
    "            \n",
    "            \n",
    "#             # Create the DataLoaders for our training and validation sets.\n",
    "#             # We'll take training samples in random order. \n",
    "#             train_dataloader = DataLoader(\n",
    "#                         train_gender_data_pairs,  # The training samples.\n",
    "#                         sampler = RandomSampler(train_gender_data_pairs), # Select batches randomly\n",
    "#                         batch_size = batch_size # Trains with this batch size.\n",
    "#                     )\n",
    "        \n",
    "           \n",
    "#             print(\"epoch:\", epoch)\n",
    "#             for step, batch in enumerate(train_dataloader):\n",
    "#                 # print(step)\n",
    "#                 # print(batch.shape)\n",
    "#                 # bertflow.train()\n",
    "#                 z, loss = bertflow(batch.to(device))  # Here z is the sentence embedding\n",
    "#                 if step%100==0:\n",
    "#                     print(loss)\n",
    "#                     print(loss, file=open('output.txt', 'a'))\n",
    "#                 optimizer.zero_grad()\n",
    "#                 loss.backward()\n",
    "#                 optimizer.step()\n",
    "        \n",
    "#             # if (iteration)%4500==0:\n",
    "#             # if (epoch+1)%4==0:\n",
    "#             torch.save(bertflow, model_path+'/bertflow_rho_0999_factors_6_iterations_'+str(iteration)+'.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "603a8497-7f39-44c7-8494-faa9b0617f3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d08134-b19d-47b9-ab36-2868df958ac3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
