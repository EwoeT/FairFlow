{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f893f691-013c-4a65-a360-8d1a59528257",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "We will use the GPU: NVIDIA A40\n"
     ]
    }
   ],
   "source": [
    "# import tensorflow as tf\n",
    "import numpy as np\n",
    "import torch\n",
    "import random\n",
    "import pandas as pd\n",
    "import os, sys\n",
    "import time\n",
    "import datetime\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torch.nn import CrossEntropyLoss, MSELoss\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "# random.seed(42)\n",
    "torch.manual_seed(42) \n",
    "if torch.cuda.is_available():\n",
    "  device = torch.device(\"cuda\")\n",
    "  print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "  print('We will use the GPU:', torch.cuda.get_device_name())\n",
    "\n",
    "else:\n",
    "  print('No GPU available, using the CPU instead.')\n",
    "  device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eec8e182-4e50-42b0-b14b-a69f25331287",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForMaskedLM were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['discriminator_predictions.dense.bias', 'discriminator_predictions.dense.weight', 'discriminator_predictions.dense_prediction.bias', 'discriminator_predictions.dense_prediction.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForMaskedLM(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (discriminator_predictions): BertDiscriminatorPredictions(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dense_prediction): Linear(in_features=768, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "attribute_pair = \"african_european\"\n",
    "embeddings_path = \"attribute_embeddings_\"+attribute_pair\n",
    "if not os.path.exists(embeddings_path):\n",
    "    os.makedirs(embeddings_path)\n",
    "\n",
    "# discriminator = torch.load(\"classification_model_\"+attribute_pair+\"_9.pth\")\n",
    "import bert_model_2_extract_attributes_after_training\n",
    "# import importlib\n",
    "# importlib.reload(bert_model_2_extract_attributes_after_training)\n",
    "BertForMaskedLM = bert_model_2_extract_attributes_after_training.BertForMaskedLM\n",
    "\n",
    "model = BertForMaskedLM.from_pretrained(\"bert-base-uncased\", attribute_pair, max_token_count=70, threshold=8)\n",
    "# model.load_state_dict(discriminator.state_dict())\n",
    "# model = torch.nn.DataParallel(model, device_ids=None)\n",
    "for param in model.parameters():\n",
    "    # print(param)\n",
    "    param.requires_grad = False\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c90e498-350f-46ed-a3b1-5d39f2c56567",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "vocabs = tokenizer.get_vocab()\n",
    "vv = dict((v,k) for k,v in vocabs.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6902d9e1-5e95-4e61-8dde-4ee69601c085",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (vv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e0fb7be3-2041-4e75-98fc-6b914ee87c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('../../DIIN/data/enwiki-20230320-pages-articles3.txt') as file:\n",
    "#     lines = [line.rstrip() for line in file]\n",
    "# attribute_df2 = pd.DataFrame(lines)[0]\n",
    "# attribute_df2.reset_index(drop=True)\n",
    "# attribute_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "260b4b65-9c47-46bf-b6f2-78da5db7403c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# torch.save(train_dataset, '2_attribute_tokenized/train_attribute_attributes_tokens.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "44738309-2434-4c98-a3a3-3c47376cd95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import time\n",
    "import datetime\n",
    "import pickle\n",
    "from transformers.optimization import AdamW\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "# The DataLoader needs to know our batch size for training, so we specify it \n",
    "# here. For fine-tuning BERT on a specific task, the authors recommend a batch \n",
    "# size of 16 or 32.\n",
    "batch_size = 32\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from transformers.optimization import get_linear_schedule_with_warmup\n",
    "\n",
    "# Number of training epochs. The BERT authors recommend between 2 and 4. \n",
    "# We chose to run for 4, but we'll see later that this may be over-fitting the\n",
    "# training data.\n",
    "# epochs = 4\n",
    "\n",
    "# Total number of training steps is [number of batches] x [number of epochs]. \n",
    "# (Note that this is not the same as the number of training samples).\n",
    "# total_steps = len(test_dataloader) * epochs\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def format_time(elapsed):\n",
    "    '''\n",
    "    Takes a time in seconds and returns a string hh:mm:ss\n",
    "    '''\n",
    "    # Round to the nearest second.\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    \n",
    "    # Format as hh:mm:ss\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))\n",
    "\n",
    "# import numpy as np\n",
    "\n",
    "\n",
    "# Function to calculate the accuracy of our predictions vs labels\n",
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
    "\n",
    "\n",
    "import random\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# This training code is based on the `run_glue.py` script here:\n",
    "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
    "def train(model, test_dataloader):\n",
    "    seed_val = 42\n",
    "\n",
    "    random.seed(seed_val)\n",
    "    np.random.seed(seed_val)\n",
    "    torch.manual_seed(seed_val)\n",
    "    torch.cuda.manual_seed_all(seed_val)\n",
    "\n",
    "    # We'll store a number of quantities such as training and validation loss, \n",
    "    # validation accuracy, and timings.\n",
    "    training_stats = []\n",
    "\n",
    "    # Measure the total training time for the whole run.\n",
    "    total_t0 = time.time()\n",
    "\n",
    "    # For each epoch...\n",
    "#     t = tqdm(range(start_epoch,epochs))\n",
    "\n",
    "#     for epoch_i in t:\n",
    "\n",
    "   \n",
    "\n",
    "    # ========================================\n",
    "    #               Validation\n",
    "    # ========================================\n",
    "    # After the completion of each training epoch, measure our performance on\n",
    "    # our validation set.\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"Running Extraction...\")\n",
    "\n",
    "    t0 = time.time()\n",
    "\n",
    "    # Put the model in evaluation mode--the dropout layers behave differently\n",
    "    # during evaluation.\n",
    "    model.eval()\n",
    "\n",
    "    # Tracking variables \n",
    "    total_eval_accuracy = 0\n",
    "    total_eval_loss = 0\n",
    "    nb_eval_steps = 0\n",
    "\n",
    "    all_embeddings = []\n",
    "    all_gen_labels = []\n",
    "    all_attribute_token_id = []\n",
    "    all_logits = []\n",
    "    # Evaluate data for one epoch\n",
    "    jj=0\n",
    "\n",
    "    count_dict = {}\n",
    "    for i in tokenizer.vocab.values():\n",
    "        count_dict[i] = 0\n",
    "\n",
    "    \n",
    "    \n",
    "    for batch in test_dataloader:\n",
    "        jj=jj+1\n",
    "        if jj%100==0:\n",
    "            print(jj)\n",
    "\n",
    "        # Unpack this training batch from our dataloader. \n",
    "        #\n",
    "        # As we unpack the batch, we'll also copy each tensor to the GPU using \n",
    "        # the `to` method.\n",
    "        #\n",
    "        # `batch` contains three pytorch tensors:\n",
    "        #   [0]: input ids \n",
    "        #   [1]: attention masks\n",
    "        #   [2]: labels \n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        # ster_labels = batch[4]\n",
    "\n",
    "\n",
    "\n",
    "        # Tell pytorch not to bother with constructing the compute graph during\n",
    "        # the forward pass, since this is only needed for backprop (training).\n",
    "        with torch.no_grad():        \n",
    "            # Perform a forward pass (evaluate the model on this training batch).\n",
    "            # The documentation for this `model` function is here: \n",
    "            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
    "            # It returns different numbers of parameters depending on what arguments\n",
    "            # arge given and what flags are set. For our useage here, it returns\n",
    "            # the loss (because we provided labels) and the \"logits\"--the model\n",
    "            # outputs prior to activation.\n",
    "            embeddings, token_ids, gender, logits, count_dict = model(b_input_ids, \n",
    "                                 # token_type_ids=None,\n",
    "                                 count_dict=count_dict,\n",
    "                                 attention_mask=b_input_mask, \n",
    "                                 # labels=b_target_labels,\n",
    "                                )\n",
    "\n",
    "            # print(len(res))\n",
    "            # res = embeddings.cpu().detach().numpy()\n",
    "            # print(len(res), len(b_target_labels))\n",
    "            for key, iii in enumerate(embeddings):\n",
    "                all_embeddings.append(list(iii.cpu().detach().numpy()))\n",
    "                # print(all_embeddings)\n",
    "                all_attribute_token_id.append(token_ids[key].cpu().detach().numpy().item())\n",
    "                # print(all_attribute_token_id)\n",
    "                all_gen_labels.append(gender[key])\n",
    "                # print(all_gen_labels)\n",
    "                all_logits.append(logits[key].cpu().detach().numpy().item())\n",
    "\n",
    "        # if jj<=20000:\n",
    "            if jj%30000==0:\n",
    "                # ccc = {vv[k]:v for k,v in count_dict.items()}\n",
    "                # print(ccc)\n",
    "                with open(embeddings_path+\"/embeddings_\"+str(jj)+\".pkl\", 'wb') as f:\n",
    "                    pickle.dump(all_embeddings, f)\n",
    "                with open(embeddings_path+\"/token_ids_\"+str(jj)+\".pkl\", 'wb') as f:\n",
    "                    pickle.dump(all_attribute_token_id, f)\n",
    "                with open(embeddings_path+\"/gender_\"+str(jj)+\".pkl\", 'wb') as f:\n",
    "                    pickle.dump(all_gen_labels, f)\n",
    "                with open(embeddings_path+\"/logits_\"+str(jj)+\".pkl\", 'wb') as f:\n",
    "                    pickle.dump(all_logits, f)\n",
    "    \n",
    "                all_embeddings = []\n",
    "                all_gen_labels = []\n",
    "                all_attribute_token_id = []\n",
    "                all_logits = []\n",
    "    \n",
    "    # # ccc = {vv[k]:v for k,v in count_dict.items()}\n",
    "    # # print(ccc)\n",
    "    # with open(embeddings_path+\"/embeddings_\"+str(jj)+\".pkl\", 'wb') as f:\n",
    "    #     pickle.dump(all_embeddings, f)\n",
    "    # with open(embeddings_path+\"/token_ids_\"+str(jj)+\".pkl\", 'wb') as f:\n",
    "    #     pickle.dump(all_attribute_token_id, f)\n",
    "    # with open(embeddings_path+\"/gender_\"+str(jj)+\".pkl\", 'wb') as f:\n",
    "    #     pickle.dump(all_gen_labels, f)\n",
    "    # with open(embeddings_path+\"/logits_\"+str(jj)+\".pkl\", 'wb') as f:\n",
    "    #     pickle.dump(all_logits, f)\n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "432d9e33-fa3a-43f1-bd41-7a8441aef066",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = torch.load('1_train_dataset1.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "89cec420-9ac6-4fc1-884b-fdba36f9e05b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running Extraction...\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "2200\n",
      "2300\n",
      "2400\n",
      "2500\n",
      "2600\n",
      "2700\n",
      "2800\n",
      "2900\n",
      "3000\n",
      "3100\n",
      "3200\n",
      "3300\n",
      "3400\n",
      "3500\n",
      "3600\n",
      "3700\n",
      "3800\n",
      "3900\n",
      "4000\n",
      "4100\n",
      "4200\n",
      "4300\n",
      "4400\n",
      "4500\n",
      "4600\n",
      "4700\n",
      "4800\n",
      "4900\n",
      "5000\n",
      "5100\n",
      "5200\n",
      "5300\n",
      "5400\n",
      "5500\n",
      "5600\n",
      "5700\n",
      "5800\n",
      "5900\n",
      "6000\n",
      "6100\n",
      "6200\n",
      "6300\n",
      "6400\n",
      "6500\n",
      "6600\n",
      "6700\n",
      "6800\n",
      "6900\n",
      "7000\n",
      "7100\n",
      "7200\n",
      "7300\n",
      "7400\n",
      "7500\n",
      "7600\n",
      "7700\n",
      "7800\n",
      "7900\n",
      "8000\n",
      "8100\n",
      "8200\n",
      "8300\n",
      "8400\n",
      "8500\n",
      "8600\n",
      "8700\n",
      "8800\n",
      "8900\n",
      "9000\n",
      "9100\n",
      "9200\n",
      "9300\n",
      "9400\n",
      "9500\n",
      "9600\n",
      "9700\n",
      "9800\n",
      "9900\n",
      "10000\n",
      "10100\n",
      "10200\n",
      "10300\n",
      "10400\n",
      "10500\n",
      "10600\n",
      "10700\n",
      "10800\n",
      "10900\n",
      "11000\n",
      "11100\n",
      "11200\n",
      "11300\n",
      "11400\n",
      "11500\n",
      "11600\n",
      "11700\n",
      "11800\n",
      "11900\n",
      "12000\n",
      "12100\n",
      "12200\n",
      "12300\n",
      "12400\n",
      "12500\n",
      "12600\n",
      "12700\n",
      "12800\n",
      "12900\n",
      "13000\n",
      "13100\n",
      "13200\n",
      "13300\n",
      "13400\n",
      "13500\n",
      "13600\n",
      "13700\n",
      "13800\n",
      "13900\n",
      "14000\n",
      "14100\n",
      "14200\n",
      "14300\n",
      "14400\n",
      "14500\n",
      "14600\n",
      "14700\n",
      "14800\n",
      "14900\n",
      "15000\n",
      "15100\n",
      "15200\n",
      "15300\n",
      "15400\n",
      "15500\n",
      "15600\n",
      "15700\n",
      "15800\n",
      "15900\n",
      "16000\n",
      "16100\n",
      "16200\n",
      "16300\n",
      "16400\n",
      "16500\n",
      "16600\n",
      "16700\n",
      "16800\n",
      "16900\n",
      "17000\n",
      "17100\n",
      "17200\n",
      "17300\n",
      "17400\n",
      "17500\n",
      "17600\n",
      "17700\n",
      "17800\n",
      "17900\n",
      "18000\n",
      "18100\n",
      "18200\n",
      "18300\n",
      "18400\n",
      "18500\n",
      "18600\n",
      "18700\n",
      "18800\n",
      "18900\n",
      "19000\n",
      "19100\n",
      "19200\n",
      "19300\n",
      "19400\n",
      "19500\n",
      "19600\n",
      "19700\n",
      "19800\n",
      "19900\n",
      "20000\n",
      "20100\n",
      "20200\n",
      "20300\n",
      "20400\n",
      "20500\n",
      "20600\n",
      "20700\n",
      "20800\n",
      "20900\n",
      "21000\n",
      "21100\n",
      "21200\n",
      "21300\n",
      "21400\n",
      "21500\n",
      "21600\n",
      "21700\n",
      "21800\n",
      "21900\n",
      "22000\n",
      "22100\n",
      "22200\n",
      "22300\n",
      "22400\n",
      "22500\n",
      "22600\n",
      "22700\n",
      "22800\n",
      "22900\n",
      "23000\n",
      "23100\n",
      "23200\n",
      "23300\n",
      "23400\n",
      "23500\n",
      "23600\n",
      "23700\n",
      "23800\n",
      "23900\n",
      "24000\n",
      "24100\n",
      "24200\n",
      "24300\n",
      "24400\n",
      "24500\n",
      "24600\n",
      "24700\n",
      "24800\n",
      "24900\n",
      "25000\n",
      "25100\n",
      "25200\n",
      "25300\n",
      "25400\n",
      "25500\n",
      "25600\n",
      "25700\n",
      "25800\n",
      "25900\n",
      "26000\n",
      "26100\n",
      "26200\n",
      "26300\n",
      "26400\n",
      "26500\n",
      "26600\n",
      "26700\n",
      "26800\n",
      "26900\n",
      "27000\n",
      "27100\n",
      "27200\n",
      "27300\n",
      "27400\n",
      "27500\n",
      "27600\n",
      "27700\n",
      "27800\n",
      "27900\n",
      "28000\n",
      "28100\n",
      "28200\n",
      "28300\n",
      "28400\n",
      "28500\n",
      "28600\n",
      "28700\n",
      "28800\n",
      "28900\n",
      "29000\n",
      "29100\n",
      "29200\n",
      "29300\n",
      "29400\n",
      "29500\n",
      "29600\n",
      "29700\n",
      "29800\n",
      "29900\n",
      "30000\n",
      "30100\n",
      "30200\n",
      "30300\n",
      "30400\n",
      "30500\n",
      "30600\n",
      "30700\n",
      "30800\n",
      "30900\n",
      "31000\n",
      "31100\n",
      "31200\n",
      "31300\n",
      "31400\n",
      "31500\n",
      "31600\n",
      "31700\n",
      "31800\n",
      "31900\n",
      "32000\n",
      "32100\n",
      "32200\n",
      "32300\n",
      "32400\n",
      "32500\n",
      "32600\n",
      "32700\n",
      "32800\n",
      "32900\n",
      "33000\n",
      "33100\n",
      "33200\n",
      "33300\n",
      "33400\n",
      "33500\n",
      "33600\n",
      "33700\n",
      "33800\n",
      "33900\n",
      "34000\n",
      "34100\n",
      "34200\n",
      "34300\n",
      "34400\n",
      "34500\n",
      "34600\n",
      "34700\n",
      "34800\n",
      "34900\n",
      "35000\n",
      "35100\n",
      "35200\n",
      "35300\n",
      "35400\n",
      "35500\n",
      "35600\n",
      "35700\n",
      "35800\n",
      "35900\n",
      "36000\n",
      "36100\n",
      "36200\n",
      "36300\n",
      "36400\n",
      "36500\n",
      "36600\n",
      "36700\n",
      "36800\n",
      "36900\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "            train_dataset, # The validation samples.\n",
    "            sampler = SequentialSampler(train_dataset), # Pull out batches sequentially.\n",
    "            batch_size = batch_size # Evaluate with this batch size.\n",
    "            )\n",
    "    \n",
    "train(model, train_dataloader)\n",
    "    # time.sleep(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7f819517-623e-4632-bb86-6e86d9c0576a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('../../DIIN/data/intrinsic_word_level_data/enwiki-20230320-pages-articles3.txt') as file:\n",
    "#     # with open('../iterative_adversarial/CDA/0_model/final_files/data/MBCDA2_jigsaw.txt') as file:\n",
    "# # with open('../DIIN/data/enwiki-20230320-pages-articles8.txt') as file:\n",
    "#     lines = [line.rstrip() for line in file]\n",
    "# attribute_df6 = pd.DataFrame(lines)[0]\n",
    "# attribute_df6.reset_index(drop=True)\n",
    "# text_list = list(attribute_df6[5000:8000])\n",
    "\n",
    "# text_input_tokenized = tokenizer.batch_encode_plus(text_list, truncation=True, max_length=50, padding=True, return_tensors=\"pt\")\n",
    "# inputs = text_input_tokenized[\"input_ids\"].to(\"cuda\")\n",
    "# attention_mask = text_input_tokenized[\"attention_mask\"]\n",
    "# # text_input_tokenized\n",
    "# inputs2 = inputs.clone()\n",
    "\n",
    "\n",
    "# from torch.utils.data import TensorDataset\n",
    "\n",
    "# train_dataset = TensorDataset(inputs2, attention_mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c83f7144-892c-48c2-9071-dbea95140e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('../../DIIN/data/intrinsic_word_level_data/enwiki-20230320-pages-articles3.txt') as file:\n",
    "#     # with open('../iterative_adversarial/CDA/0_model/final_files/data/MBCDA2_jigsaw.txt') as file:\n",
    "# # with open('../DIIN/data/enwiki-20230320-pages-articles8.txt') as file:\n",
    "#     lines = [line.rstrip() for line in file]\n",
    "# attribute_df6 = pd.DataFrame(lines)[0]\n",
    "# attribute_df6.reset_index(drop=True)\n",
    "# text_list = attribute_df6[:]\n",
    "\n",
    "# text_list = list(text_list)\n",
    "\n",
    "# ratio = 300000\n",
    "# start_ind = 0\n",
    "# end_ind = 0\n",
    "\n",
    "# for i in range(int(len(text_list)/ratio)):\n",
    "#     print(i)\n",
    "#     end_ind+=ratio\n",
    "#     text_input_tokenized = tokenizer.batch_encode_plus(text_list[start_ind:end_ind], truncation=True, max_length=150, padding=True, return_tensors=\"pt\")\n",
    "#     input_ids = text_input_tokenized[\"input_ids\"].to(\"cuda\")\n",
    "#     attention_mask = text_input_tokenized[\"attention_mask\"]\n",
    "#     start_ind += ratio\n",
    "    \n",
    "#     from torch.utils.data import TensorDataset\n",
    "    \n",
    "#     train_dataset = TensorDataset(input_ids, attention_mask)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#     train_dataloader = DataLoader(\n",
    "#             train_dataset, # The validation samples.\n",
    "#             sampler = SequentialSampler(train_dataset), # Pull out batches sequentially.\n",
    "#             batch_size = batch_size # Evaluate with this batch size.\n",
    "#             )\n",
    "    \n",
    "#     # Start\n",
    "#     start_epoch = 0\n",
    "    \n",
    "#     # Logger\n",
    "#     losslogger = pd.DataFrame()\n",
    "    \n",
    "#     # Checkpoint name\n",
    "#     checkpoint_name = 'checkpoint.pth.tar'\n",
    "    \n",
    "#     train(model, train_dataloader, i)\n",
    "#     time.sleep(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0ac26e29-6123-474b-920b-bacc78d5b7a6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'text_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mlen\u001b[39m(\u001b[43mtext_list\u001b[49m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'text_list' is not defined"
     ]
    }
   ],
   "source": [
    "len(text_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350e416a-81c1-4b32-8ff5-55d8d6b634b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "1140679/300000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6e7030-9e25-4a5e-a44b-76b5c7b1d39f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "464d862c-bb4f-460a-8ede-d2defe36d61b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# embeddings_path = \"attribute_embeddings\"\n",
    "# if not os.path.exists(embeddings_path):\n",
    "#     os.makedirs(embeddings_path)\n",
    "\n",
    "\n",
    "# discriminator_outputs = discriminator(inputs)\n",
    "# predictions = discriminator_outputs.logits\n",
    "# preds = predictions.squeeze().tolist()\n",
    "# # output_ids = list(map(identify_fake_tokens, inputs, preds))\n",
    "# embeddings, token_ids, gender = tokenizer.batch_decode(inputs, skip_special_tokens=True, clean_up_tokenization_spaces=False)\n",
    "\n",
    "            \n",
    "# with open(\"attribute_embeddings/embeddings.pkl\", 'wb') as f:\n",
    "#     pickle.dump(embeddings, f)\n",
    "# with open(\"attribute_embeddings/token_ids.pkl\", 'wb') as f:\n",
    "#     pickle.dump(token_ids, f)\n",
    "# with open(\"attribute_embeddings/gender.pkl\", 'wb') as f:\n",
    "#     pickle.dump(gender, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521210a9-f196-4d5c-807a-753cf48d0b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# attention_mask = attention_mask.numpy()\n",
    "# # attention_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac84b98e-f684-47fe-8cb1-c809b57e512c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vocabsss = tokenizer.get_vocab()\n",
    "# vocabs = dict((v,k) for k,v in vocabsss.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6574075a-fd1e-486e-b4a8-a6a5aaf2c110",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(100):\n",
    "#     index =i\n",
    "#     text_in = [vocabs[i] for i in inputs2[index].cpu().numpy()]\n",
    "#     # print(text_in)\n",
    "#     try:\n",
    "#         preddd = [i for i in preds[index]]\n",
    "#     except:\n",
    "#         preddd = preds\n",
    "#     text_in = [vocabs[j] for k,j in enumerate(inputs2[index].cpu().numpy()) if attention_mask[index][k]==1]\n",
    "#     preddd = [j for k,j in enumerate(preddd) if attention_mask[index][k]==1]\n",
    "#     preddd = [j for k,j in enumerate(preddd) if (text_in[k].startswith('##')==False and text_in[k]!='.' and text_in[k]!='?'\n",
    "#     and text_in[k]!='!' and text_in[k]!=\",\" and text_in[k]!=\"n't\"\n",
    "#     and text_in[k]!=\"'m\" and text_in[k]!=\"'s\" and text_in[k]!=\"'ve\" and text_in[k]!=\"'re\"\n",
    "#     and text_in[k]!=\"[UNK]\")]# and text_in[k].startswith(\"(\")==False and text_in[k].startswith(\")\")==False and text_in[k].startswith(\"-\")==False)]\n",
    "#     # and text_in[k].startswith(\":\")==False and text_in[k].startswith(\"(\")==False and text_in[k].startswith(\")\")==False and text_in[k].startswith(\"-\")==False)]\n",
    "#     preddd = preddd[1:-1]\n",
    "#     text_in = text_in[1:-1]\n",
    "    \n",
    "    \n",
    "#     words = output_texts[index].split()\n",
    "#     # print(text_in)\n",
    "#     # print(words)\n",
    "#     if len(words) == len(preddd):\n",
    "#         s = colorize(words, NormalizeData(preddd))\n",
    "#         # to display in ipython notebook\n",
    "#         print(len(words), len(preddd))\n",
    "#         print(NormalizeData(preddd))\n",
    "#         display(HTML(s))\n",
    "#     else:\n",
    "#         print(\"process failed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf722fe4-8c76-4383-94e4-177fdf03fb96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# discriminator_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d195e05e-3f7d-4b52-b3b1-8026ca7a4a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6098586d-c2f6-4a04-ab35-abfaf6f97185",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preddd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69113108-0325-41aa-b6b8-0c3e97d9cf02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad0c1aaf-0ea5-4f8c-8829-c488a859c40c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af121555-aeee-4ccb-acca-5cf4c22680bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in tokenizer.vocab.values():\n",
    "#     print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25394664-cf05-447f-9802-9f70b3d363d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
